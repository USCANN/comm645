---
title: "ERGM"
author: "Joshua Clark"
date: "10/13/2015"
output: html_document
---

As is traditional in ergm tutorials, we'll use the Padgett florentine marriage & business ties dataset included with the ergm package:

```{r}
library(ergm)
data(florentine) 
```
The data contains two network objects - one with marital and another one with business relationships between Florentine families.
```{r}
flobusiness
flomarriage
```

Exponential random graph models - what terms can we use in a model?

```{r}
help('ergm-terms')
```

Let's estimate a simple  model which only examines density (edge term) the format of the ergm command is ergm(YourNetwork ~ Signature1 + Signature2 + ...) where YourNetwork can be a matrix or a network object.
```{r}
flo.mar.1 <- ergm(flomarriage ~ edges)  		 
flo.mar.1
summary(flo.mar.1)
```
We get a negative edge parameter since the network is rather sparse. The edge parameter here is the log of the edge odds, i.e. log(dyads-w-edge/dyads-no-edge. The network has 20 ties of 120 possible ties. Let's calculate the log odds ourselves: remember that an event with probability p has odds of p/(1-p) and log odds of log(p/(1-p)).

```{r}
log(20/(120-20)) # We get -1.609, the same as the edge parameter in the erg model.

# The corresponding probability is .167:
exp(-1.609)/(1+exp(-1.609)) # you can also get that using inv.logit() from package "boot"
```

Next we look at a fancier model that includes triangles in addition to edges:
```{r}
flo.mar.2 <- ergm(flomarriage ~ edges + triangles, control=control.ergm(seed=1))    	 
flo.mar.2
summary(flo.mar.2)
```
The triangle coefficient is not significant - so this is not a signature  driving the network formation. What do the coefficients tell us?

Conditional log-odds of a tie between two actors here = -1.675*(change in the number of ties) + 0.158 * (change in the number of triangles) -1.675*1 + 0.158*(change in the number of triangles)

If the tie will not add any triangles to the network, its log-odds = -1.675.
If it will add one triangle to the network, its log-odds = -1.675 + 0.158 = -1.517
If it will add two triangles to the network, its log-odds = -1.675 + 0.158*2 = -1.359

The corresponding probabilities are 0.158, 0.180, and 0.204.


There are a large number of other structural signatures you could add paramteters for. For instance 2-stars: kstar(2), 3-stars: kstar(3) isolates: isolates, etc. 

Let's run a model checking whether edges in the Florentine business network are predicted by edges in the marriage network. To do that, we can use an edge covariate parameter edgecov()

As in: ergm(MyNetwork ~ Signature1 + Signature2 + ... + edgecov(AnotherNetwork))

```{r}
flo.mar.3 <- ergm(flobusiness ~ edges + edgecov(flomarriage), control=control.ergm(seed=1))       
flo.mar.3
summary(flo.mar.3)
```

We can also use node attributes in an erg model.
For the Florentine families, we have an attribute called "wealth" in the network object.

```{r}
w.vec <- flomarriage %v% 'wealth'  # Store the node wealth in a numeric vector.
w.vec
plot(flomarriage, vertex.cex=w.vec/20)	# plot the network with vertex size proportional to wealth
```


Let's test whether the edge probabilities are a function of wealth: Are wealthy families more likely to form ties?  

```{r}
flo.mar.4 <- ergm(flomarriage ~ edges + nodecov("wealth"), control=control.ergm(seed=1))       
flo.mar.4
summary(flo.mar.4)
```

Yes, there is a significant positive main effect for wealth:
- The p-value for the wealth parameter makes it significant at the .05 level.
- It's positive, which means we see more of that configuratoin than we'd expect by chance.


### ERGM on a directed network: Sampson Monastery


ERG model of a directed network - the liking relations between monks in Sampson's dataset.

```{r}
data(samplk)
samplk1
samplk2
samplk3
plot(samplk3)
```

Is there a statistically significant tendency for ties to be reciprocated?
```{r}
samp.mod.1 <- ergm(samplk3 ~ edges + mutual, control=control.ergm(seed=1))	
summary(samp.mod.1)				
```
Conditional log-odds of two actors forming a tie = -2.15 * change in the number of ties + 2.3 * change in number of mutual dyads. 

If adding the tie will not make a dyad reciprocal, its log-odds = -2.15
If it will add a mutual dyad to the network, its log-odds = -2.15 + 2.3 = 0.15  

### ERGM with node attributes: Faux Mesa High


Faux mesa high is simulated data representing a high-school friendship network. Attributes for each node (student) include gender, race, and grade.

```{r}
data(faux.mesa.high)  			
fmh.net <- faux.mesa.high
plot(fmh.net)						
fmh.net
```

Taking a look at gender.
```{r}
plot(fmh.net, vertex.col='Sex')
```

Taking a look at the grade of the students
```{r}
plot(fmh.net, vertex.col='Grade') 
```

Taking a look at the race of the students
```{r}
plot(fmh.net, vertex.col='Race') 
```

A simple model that includes just the edge (density) parameter:

```{r}
fmh.mod.1 <- ergm(fmh.net ~ edges)
summary(fmh.mod.1)
```

**NODEMATCH**

Are nodes with the same attribute levels more likely to be connected?

Do high-school students tend to have friends of the same grade?

```{r}
fmh.mod.2 <- ergm(fmh.net ~ edges + nodematch("Grade"), control=control.ergm(seed=1))
summary(fmh.mod.2)
```

We can add an attribute diff=T to nodematch to get a separate parameter for each level of the categorical variable. Here, a separate parameter for each grade:

```{r}
fmh.mod.3 <- ergm(fmh.net ~ edges + nodematch("Grade", diff=T), control=control.ergm(seed=1))
summary(fmh.mod.3)
```

How about gender and race?  

```{r}
fmh.mod.4 <- ergm(fmh.net ~ edges + nodematch("Grade") + nodematch("Race") + nodematch("Sex"), control=control.ergm(seed=1))
summary(fmh.mod.4)
```

**NODEMIX**

Nodemix will add a parameter for each combination of levels for the categorical variable. Let's look at the parameters for edges between students from different race groups:

```{r}
fmh.mod.5 <- ergm(fmh.net ~ edges + nodemix("Race"), control=control.ergm(seed=1))
summary(fmh.mod.5)
table(fmh.net %v% "Race")  			# Check out race frequencies
mixingmatrix(fmh.net, "Race")   # Check out # of links between/within groups
```

Note that we got -Inf parameters in the model for configurations that don't exist in the observed network at all.

**NODEFACTOR**

Main effect of a categorical attribute. Are some types of nodes more likely to form ties than others? For example, are boys forming friendship ties more actively than girls?

```{r}
fmh.mod.6 <- ergm(fmh.net ~ edges + nodematch("Grade", diff = T) + nodefactor("Sex"), control=control.ergm(seed=1))
summary(fmh.mod.6)
```

Negative parameter for males means females are more actively forming friendships.

**NODECOV**

Main effect of a continuous attribute (we'll treat grade as continuous here). Are nodes with high levels on a continuous attribute more likely to form ties? Let's check if students with higher values on attribute "Grade" tend to form more friendships.

```{r}
fmh.mod.7 <- ergm(fmh.net ~ edges + nodecov("Grade") + nodematch("Sex"), control=control.ergm(seed=1))
summary(fmh.mod.7)
```

Note that this is the parameter version for undirected networks. For directed networks, we have nodeicov (for incoming links) and nodeocov (for outgoing links). Similarly nodefactor has directev versions nodeifactor & nodeofactor.


**ABSDIFF**

For continuous attributes: are people more likely to be connected to others who have similar values on an attribute? Absdiff = abs(ValueNode1-ValueNode2). Here, are students more likely to have friends close to their own grade? that is, links i->j are more likely for smaller values of abs(grade of i - grade of j))

```{r}
fmh.mod.8 <- ergm(fmh.net ~ edges + absdiff("Grade") + nodematch("Sex"), control=control.ergm(seed=1))
summary(fmh.mod.8)
```

###Simulating networks based on a model

After we have estimated model coefficients, we can draw graphs from the probability distribution defined by those parameter values. If our model was good, the graphs we draw from this distribution should be similar to our observed data.

**Simulate 15 networks based on the fmh.mod.6 model:**

```{r}
fmh.mod.8.sim <- simulate(fmh.mod.8, nsim=15)
summary(fmh.mod.8.sim)

#' All the simulated network are stored in the returned object:
class(fmh.mod.8.sim)

#' We can access any of them and take a look at it:
fmh.mod.8.sim[[1]]
```


###Goodnes of Fit and MCMC diagnostics

After estimating parameters for your mode, you want to know how well it fits the observed data.

Let's check the goodness of fit for one of our initial models of the Padgett network. Check how well the degree distribution of the networs generated from our model match the degree distribution of the observed network:

```{r}
summary(flo.mar.4) # Take a look at the model

flo.mar.4.gof <- gof(flo.mar.4 ~ degree) # goodness of fit for degree distribution
```
If this was a directed network, we could check gof for in- or out-degree instead using gof(flo.mar.4 ~ idegree) or gof(flo.mar.4 ~ odegree)

```{r}
flo.mar.4.gof # Take a look at the observed & simulated values
plot(flo.mar.4.gof) # plot the observed & simulated values
```
The resutls contain 1 row for each possible node degree (e.g. row 0 - number of isolates, row 1 - number of nodes with only 1 link, row 2 - # of nodes with 2 links, etc.)

The first column contains the counts from the observed network, the other give staticstics from the simulated networks.  

The fit is not bad - observed values are within the confidence interval (see the plot).
P values are high (the observed & simulated values do not differ significantly). This is one of those rare cases where a high p value is a good thing :)

We can check the goodness of fit with regard to other network statistics. For instance geodesic distance.

Compare our network with 20 simulated networks based on the flo.mar.4 model:

```{r}
flo.mar.4.gof2 <- gof(flo.mar.4 ~ distance, nsim=20) # gof based on 20 simulated nets
summary(flo.mar.4.gof2)
plot(flo.mar.4.gof2)
```

Here each row in the summary is the number of geodesics with a particular length. For instance, we have 20 node pairs in the observed network with shortest paths of 1 (those correspond to the 20 edges in our observed network).


### Model diagnostics (for MCMC)

Information about the model that can help diagnose problems. Note we can't get (and don't need) these diagnostics for flo.mar.4 since it was not estimated using MCMC. This is because it was simple enough (i.e. a dyadic independence model) that we did not need MCMC estimation.

```{r}
mcmc.diagnostics(flo.mar.2)
```


We can examine the diagnostics to see whether our model looks ok, check for model degeneracy, see if MCMC sample size and burn-in are large enough, etc.  Read more about interpreting model diagnostics in Section 5 of [this document](http://statnet.csde.washington.edu/trac/raw-attachment/wiki/Resources/ERGMtutorial.pdf)

### Degeneracy 

Degeneracy happens when the simulation of new networks gets "stuck" and you end up with a lot of garbage networks which don't reflect the base reality of your data. It is important to find and diagnose these models as they can seriously skew the quality of your work.

Broadly speaking there are two categories of degeneracy. Converging and non-converging. The first occurs when your model fits but the MCMC diagnostics output some weirdness.

```{r}
flo.degen.1<-ergm(flobusiness~edges+degree(1))
mcmc.diagnostics(flo.degen.1)
```

Woah, that second graph is super spikey and un-cool looking. We want a smooth fit centered at or around zero. We can fix this simply by dropping degree(1) from the model.

Now the second and objectively more terrifying kind of degenerecy. When everything blows up. Let's load another fake highschool dataset and fit a model.

```{r error=TRUE}
data(faux.magnolia.high)
faux.degen.1<- ergm(faux.magnolia.high~edges+triangle)
```

Welp. Triangles kinda broke the model. The triangle function is notorious for doing this. There is an alternative GWESP (Geometrically Weighted Edgewise Shared Parameter) which gets at roughly the same process with a lot less pain.

```{r}
faux.degen.2 <- ergm(faux.magnolia.high~edges+gwesp(0.25,fixed=T))
mcmc.diagnostics(faux.degen.2)
```

Better but still not amazing. Let's open up the hood with control.ergm and tweak some things to make stuff run better.

First let's increase the MCMC sample size. This gives our chain more datapoints to play with. The interval increases the gap between each sampling point reducing autocorrelation. We can also add MCMC.burnin which discards however many cases at the start to the modelling process, giving the chain time to settle in.


```{r}

faux.degen.3 <- ergm(faux.magnolia.high~edges+gwesp(0.25,fixed=T)+nodematch('Grade')+
              nodematch('Race')+nodematch('Sex'),
            control = control.ergm(MCMC.samplesize=50000,MCMC.interval=1000, MCMC.burnin = 5000))
mcmc.diagnostics(faux.degen.3)
```

Much better! YAY!

Go forth and ERGM.